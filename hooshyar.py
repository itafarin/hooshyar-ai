import streamlit as st
import requests

# Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ secrets
HF_API_KEY = st.secrets["hf"]["api_key"]

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
st.set_page_config(page_title="Ù‡ÙˆØ´â€ŒÛŒØ§Ø± | Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯", page_icon="ğŸ“")
st.title("ğŸ“ Ù‡ÙˆØ´â€ŒÛŒØ§Ø±")
st.markdown("ğŸ‘‹ Ø¨Ù‡ Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØ­ØµÛŒÙ„ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯:")

# Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
question = st.text_input("Ø³ÙˆØ§Ù„:")

# ØªØ§Ø¨Ø¹ Ù¾Ø±Ø³Ø´ Ø§Ø² Ù…Ø¯Ù„ HuggingFace
def ask_huggingface(prompt):
    API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct"
    headers = {"Authorization": f"Bearer {HF_API_KEY}"}
    payload = {
        "inputs": prompt,
        "parameters": {"max_new_tokens": 128},
        "options": {"wait_for_model": True}
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()[0]["generated_text"]
    else:
        raise Exception(f"Ø®Ø·Ø§ Ø¯Ø± API: {response.status_code} - {response.text}")

# ÙˆÙ‚ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ø³ÙˆØ§Ù„ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†Ø¯
if question:
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´..."):
        try:
            prompt = f"Ø³ÙˆØ§Ù„ Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ­ØµÛŒÙ„ÛŒ: {question}\nÙ¾Ø§Ø³Ø®:"
            result = ask_huggingface(prompt)
            st.success("âœ… Ù¾Ø§Ø³Ø®:")
            st.write(result)
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§: {e}")
