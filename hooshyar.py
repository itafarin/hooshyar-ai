import streamlit as st
import requests

HF_API_KEY = "hf_..."  # â† Ú©Ù„ÛŒØ¯ HuggingFace Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡

st.set_page_config(page_title="Ù‡ÙˆØ´â€ŒÛŒØ§Ø± | Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯", page_icon="ğŸ“")
st.title("ğŸ“ Ù‡ÙˆØ´â€ŒÛŒØ§Ø±")
st.markdown("ğŸ‘‹ Ø¨Ù‡ Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØ­ØµÛŒÙ„ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯:")

question = st.text_input("Ø³ÙˆØ§Ù„:")

def ask_huggingface(prompt):
    API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
    headers = {"Authorization": f"Bearer {HF_API_KEY}"}
    payload = {
        "inputs": f"""Ø´Ù…Ø§ ÛŒÚ© Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±: {prompt}""",
        "options": {"wait_for_model": True}
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()[0]["generated_text"]

if question:
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´..."):
        try:
            result = ask_huggingface(question)
            st.success("âœ… Ù¾Ø§Ø³Ø®:")
            st.write(result)
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§: {e}")
